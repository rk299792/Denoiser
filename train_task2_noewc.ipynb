{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7471972d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.io import read_image\n",
    "from model import RedCNN\n",
    "from customDataset import CatdogDataset\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "from sklearn.preprocessing import normalize\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "516f1231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "gtpath=\"../dogData_60/gt/\"\n",
    "gtfiles=[]\n",
    "for folder, subfolder, filenames in os.walk(gtpath):\n",
    "    for files in filenames:\n",
    "        gtfiles.append(files)\n",
    "        \n",
    "\n",
    "noisepath=\"../dogData_60/noise/\"\n",
    "noisefiles=[]\n",
    "for folder, subfolder, filenames in os.walk(noisepath):\n",
    "    for files in filenames:\n",
    "        noisefiles.append(files)\n",
    "        \n",
    "#check whether both noise and gt have same files\n",
    "print(gtfiles==noisefiles)\n",
    "gtfiles_=gtfiles[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dc7fbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2dataset= CatdogDataset(data_path=noisepath,target_path=gtpath,filenames=gtfiles_)\n",
    "train_size=int(0.7*len(m2dataset))\n",
    "test_size=len(m2dataset)-train_size\n",
    "trainset,testset=random_split(m2dataset,[train_size,test_size],generator=torch.manual_seed(42))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e11c8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RedCNN(\n",
      "  (conv1): Conv2d(3, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (d_conv1): ConvTranspose2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (d_conv2): ConvTranspose2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (d_conv3): ConvTranspose2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (d_conv4): ConvTranspose2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (d_output): ConvTranspose2d(96, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (batchnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_dog=RedCNN()\n",
    "model_dog.load_state_dict(torch.load(\"./saved_models/task1_model.pth.tar\"))\n",
    "print(model_dog)\n",
    "criterion=nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model_dog.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f56467c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss:259.7182312011719 Batch:0\n",
      "Epoch: 1 Loss:279.15966796875 Batch:10\n",
      "Epoch: 1 Loss:248.8930206298828 Batch:20\n",
      "Epoch: 1 Loss:260.74249267578125 Batch:30\n",
      "Epoch: 1 Loss:274.3846130371094 Batch:40\n",
      "Epoch: 1 Loss:276.06561279296875 Batch:50\n",
      "Epoch: 1 Loss:271.1468811035156 Batch:60\n",
      "Epoch: 1 Loss:271.7431945800781 Batch:70\n",
      "Epoch: 1 Loss:249.69406127929688 Batch:80\n",
      "Epoch: 1 Loss:251.94764709472656 Batch:90\n",
      "Epoch: 1 Loss:248.34332275390625 Batch:100\n",
      "Epoch: 1 Loss:252.2019805908203 Batch:110\n",
      "Epoch: 1 Loss:265.9474792480469 Batch:120\n",
      "Epoch: 1 Loss:262.1739196777344 Batch:130\n",
      "Epoch: 1 Loss:251.37933349609375 Batch:140\n",
      "Epoch: 1 Loss:256.38763427734375 Batch:150\n",
      "Epoch: 1 Loss:266.0694274902344 Batch:160\n",
      "Epoch: 1 Loss:251.97119140625 Batch:170\n",
      "Epoch: 1 Loss:267.4698791503906 Batch:180\n"
     ]
    }
   ],
   "source": [
    "##Training\n",
    "optimizer.zero_grad()\n",
    "ewc_lambda=0.1\n",
    "\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(testset, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "losses_batch=[]\n",
    "trained_psnr=[]\n",
    "\n",
    "for epoch in range(2):\n",
    "    \n",
    "    for i, data in enumerate(train_loader):\n",
    "\n",
    "        inputt, target=data\n",
    "\n",
    "        target_pred=model_dog(inputt)\n",
    "\n",
    "\n",
    "\n",
    "        loss=criterion(target_pred,target)\n",
    "\n",
    "\n",
    "        losses_batch.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Epoch:{epoch} Loss:{loss.item()} Batch:{i}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6403922b",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfile=\"trained_on_dogwithout_ewc.pth.tar\"\n",
    "\n",
    "torch.save(model_dog.state_dict(),modelfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "878a454a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth PSNR(trainset): 18.688907881062395\n",
      "PSNR after applying model: 23.892375907162517\n"
     ]
    }
   ],
   "source": [
    "gt_psnr=[]\n",
    "train_psnr=[]\n",
    "for i in range(len(testset)):\n",
    "    noise,gt=testset[i]\n",
    "    gt_psnr.append(cv2.PSNR(noise.numpy(),gt.numpy()))\n",
    "    train_psnr.append(cv2.PSNR(model_dog(noise.view(-1,3,224,224)).detach().numpy().reshape(3,224,224),gt.numpy()))\n",
    "    \n",
    "print(f\"Ground Truth PSNR(trainset): {sum(gt_psnr)/len(gt_psnr)}\")\n",
    "print(f\"PSNR after applying model: {sum(train_psnr)/len(train_psnr)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc95152a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7471972d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.io import read_image\n",
    "from model import RedCNN\n",
    "from customDataset import CatdogDataset\n",
    "import cv2\n",
    "from misc import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import statistics\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "from sklearn.preprocessing import normalize\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "516f1231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "gtpath=\"../dogData_60/gt/\"\n",
    "gtfiles=[]\n",
    "for folder, subfolder, filenames in os.walk(gtpath):\n",
    "    for files in filenames:\n",
    "        gtfiles.append(files)\n",
    "        \n",
    "\n",
    "noisepath=\"../dogData_60/noise/\"\n",
    "noisefiles=[]\n",
    "for folder, subfolder, filenames in os.walk(noisepath):\n",
    "    for files in filenames:\n",
    "        noisefiles.append(files)\n",
    "        \n",
    "#check whether both noise and gt have same files\n",
    "print(gtfiles==noisefiles)\n",
    "gtfiles_=gtfiles[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dc7fbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2dataset= CatdogDataset(data_path=noisepath,target_path=gtpath,filenames=gtfiles_)\n",
    "train_size=int(0.7*len(m2dataset))\n",
    "test_size=len(m2dataset)-train_size\n",
    "trainset,testset=random_split(m2dataset,[train_size,test_size],generator=torch.manual_seed(42))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e11c8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RedCNN(\n",
      "  (conv1): Conv2d(1, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (d_conv1): ConvTranspose2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (d_conv2): ConvTranspose2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (d_conv3): ConvTranspose2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (d_conv4): ConvTranspose2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (d_output): ConvTranspose2d(96, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (batchnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_dog=RedCNN()\n",
    "model_dog.load_state_dict(torch.load(\"./saved_models/task2noewc_model.pth.tar\"))\n",
    "print(model_dog)\n",
    "criterion=nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model_dog.parameters(), lr=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f56467c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0 Loss:781.0023193359375 Batch:0\n",
      "Epoch:0 Loss:794.5599365234375 Batch:1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m     16\u001b[0m     inputt, target\u001b[38;5;241m=\u001b[39mdata\n\u001b[0;32m---> 18\u001b[0m     target_pred\u001b[38;5;241m=\u001b[39m\u001b[43mmodel_dog\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     img\u001b[38;5;241m=\u001b[39minputt\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     21\u001b[0m     img_gt\u001b[38;5;241m=\u001b[39mtarget\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/Programming folder/Denoiser-main/model.py:50\u001b[0m, in \u001b[0;36mRedCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     48\u001b[0m x2\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m     49\u001b[0m x\u001b[38;5;241m=\u001b[39mF\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatchnorm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)))\n\u001b[0;32m---> 50\u001b[0m x\u001b[38;5;241m=\u001b[39mF\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatchnorm(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m     51\u001b[0m x4\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m     52\u001b[0m x\u001b[38;5;241m=\u001b[39mF\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatchnorm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv4(x)))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py:457\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py:453\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    451\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    452\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##Training\n",
    "optimizer.zero_grad()\n",
    "\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(testset, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "losses_batch=[]\n",
    "trained_psnr=[]\n",
    "psnr=[]\n",
    "for epoch in range(3):\n",
    "    \n",
    "    for i, data in enumerate(train_loader):\n",
    "\n",
    "        inputt, target=data\n",
    "\n",
    "        target_pred=model_dog(inputt)\n",
    "        \n",
    "        img=inputt.detach().numpy()\n",
    "        img_gt=target.detach().numpy()\n",
    "        recon_image=target_pred.detach().numpy()\n",
    "        \n",
    "        \n",
    "        for j in range(len(target)):\n",
    "            psnr.append(cv2.PSNR(img[j],img_gt[j]))\n",
    "            trained_psnr.append(cv2.PSNR(img[j],recon_image[j]))\n",
    "\n",
    "        loss=criterion(target_pred,target)\n",
    "\n",
    "\n",
    "        losses_batch.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Epoch:{epoch} Loss:{loss.item()} Batch:{i}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6403922b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trained_psnrfile=\"./psnr_data/task2noewc_by_task2noewc_trainfiles.pth.tar\"\n",
    "psnr_file=\"./psnr_data/task2noewc_trainfiles.pth.tar\"\n",
    "loss_file=\"./saved_loss/task2noewc_loss.pth.tar\"\n",
    "\n",
    "torch.save(trained_psnr,trained_psnrfile)\n",
    "torch.save(psnr,psnr_file)\n",
    "torch.save(losses_batch,loss_file)\n",
    "modelfile=\"./saved_models/task2noewc_model.pth.tar\"\n",
    "\n",
    "torch.save(model_dog.state_dict(),modelfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31ea946",
   "metadata": {},
   "source": [
    "# Model Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6920c0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_images(trainset[110],testset[9],model_dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a1837e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plopling the loss vs batch\n",
    "plt.plot(list(range(22)),losses_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5c81f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##PSNR of training data\n",
    "print(f\"PSNR Training Set: {statistics.mean(psnr)}\")\n",
    "print(f\"PSNR after applying the model: {statistics.mean(trained_psnr)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c984193e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##PSNR of test data\n",
    "test_psnrfile=\"./psnr_data/task2noewc_testfiles.pth.tar\"\n",
    "test_modelpsnrfile=\"./psnr_data/task2noewc_by_task2noewc_testfiles.pth.tar\"\n",
    "\n",
    "test1_psnr=gt_psnr(testset)\n",
    "test_modelpsnr=test_psnr(testset,model_dog)\n",
    "\n",
    "torch.save(test1_psnr,test_psnrfile)\n",
    "torch.save(test_modelpsnr,test_modelpsnrfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e865d1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "task1model=RedCNN()\n",
    "task1model.load_state_dict(torch.load(\"./saved_models/task1_model.pth.tar\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e8b0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cl2modelpsnrfile=\"./psnr_data/task2_by_task1_testfiles.pth.tar\"\n",
    "test_cl2modelpsnr=test_psnr(testset,task1model)\n",
    "\n",
    "torch.save(test_cl2modelpsnr,test_cl2modelpsnrfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245538af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

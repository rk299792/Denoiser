{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0814082",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.io import read_image\n",
    "from model import RedCNN\n",
    "from customDataset import CatdogDataset\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "from sklearn.preprocessing import normalize\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02f4946c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "gtpath=\"../catData/gt/\"\n",
    "gtfiles=[]\n",
    "for folder, subfolder, filenames in os.walk(gtpath):\n",
    "    for files in filenames:\n",
    "        gtfiles.append(files)\n",
    "        \n",
    "\n",
    "noisepath=\"../catData/noise/\"\n",
    "noisefiles=[]\n",
    "for folder, subfolder, filenames in os.walk(noisepath):\n",
    "    for files in filenames:\n",
    "        noisefiles.append(files)\n",
    "        \n",
    "#check whether both noise and gt have same files\n",
    "print(gtfiles==noisefiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8ed7a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "catdataset= CatdogDataset(data_path=noisepath,target_path=gtpath,filenames=gtfiles)\n",
    "train_size=int(0.7*len(catdataset))\n",
    "test_size=len(catdataset)-train_size\n",
    "trainset,testset=random_split(catdataset,[train_size,test_size],generator=torch.manual_seed(42))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a514c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RedCNN(\n",
      "  (conv1): Conv2d(3, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (d_conv1): ConvTranspose2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (d_conv2): ConvTranspose2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (d_conv3): ConvTranspose2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (d_conv4): ConvTranspose2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (d_output): ConvTranspose2d(96, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (batchnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model=RedCNN()\n",
    "print(model)\n",
    "criterion=nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ba26af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##Training\n",
    "optimizer.zero_grad()\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(testset, batch_size=32, shuffle=True)\n",
    "\n",
    "for epoch in range(1):\n",
    "    losses=[]\n",
    "    trained_psnr=[]\n",
    "    for i, data in enumerate(train_loader):\n",
    "        \n",
    "        inputt, target=data\n",
    "        \n",
    "        target_pred=model(inputt)\n",
    "        \n",
    "        img=inputt.detach().numpy()\n",
    "        recon_image=target_pred.detach().numpy()\n",
    "        for i in range(len(target)):\n",
    "            trained_psnr.append(cv2.PSNR(img[i],recon_image[i]))\n",
    "        \n",
    "        loss=criterion(target_pred,target)\n",
    "        losses.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i%10==0):\n",
    "            print(f\"Epoch: {epoch} Loss:{loss.item()} Batch:{i}\")\n",
    "\n",
    "\n",
    "fisher_dict={}\n",
    "param_dict={}\n",
    "            \n",
    "for name, param in model.named_parameters():\n",
    "    param_dict[name] = param.data.clone()\n",
    "    fisher_dict[name] = param.grad.data.clone().pow(2)\n",
    "\n",
    "modelfile=\"trained_on_cat.pth.tar\"\n",
    "\n",
    "torch.save(model.state_dict(),modelfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b39dd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_psnr=[]\n",
    "\n",
    "for i in range(len(trainset)):\n",
    "    noise,gt=trainset[i]\n",
    "    gt_psnr.append(cv2.PSNR(noise.numpy(),gt.numpy()))\n",
    "    \n",
    "    \n",
    "print(f\"Ground Truth PSNR: {sum(gt_psnr)/len(gt_psnr)}\")\n",
    "print(f\"PSNR after training: {sum(trained_psnr)/len(trained_psnr)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

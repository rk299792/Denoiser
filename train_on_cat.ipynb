{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cc5b943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.io import read_image\n",
    "from model import RedCNN\n",
    "from customDataset import CatdogDataset\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "from sklearn.preprocessing import normalize\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a953886d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "gtpath=\"../catData/gt/\"\n",
    "gtfiles=[]\n",
    "for folder, subfolder, filenames in os.walk(gtpath):\n",
    "    for files in filenames:\n",
    "        gtfiles.append(files)\n",
    "        \n",
    "\n",
    "noisepath=\"../catData/noise/\"\n",
    "noisefiles=[]\n",
    "for folder, subfolder, filenames in os.walk(noisepath):\n",
    "    for files in filenames:\n",
    "        noisefiles.append(files)\n",
    "        \n",
    "#check whether both noise and gt have same files\n",
    "print(gtfiles==noisefiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2a4a1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "catdataset= CatdogDataset(data_path=noisepath,target_path=gtpath,filenames=gtfiles)\n",
    "train_size=int(0.7*len(catdataset))\n",
    "test_size=len(catdataset)-train_size\n",
    "trainset,testset=random_split(catdataset,[train_size,test_size],generator=torch.manual_seed(42))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09c80940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RedCNN(\n",
      "  (conv1): Conv2d(3, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (d_conv1): ConvTranspose2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (d_conv2): ConvTranspose2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (d_conv3): ConvTranspose2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (d_conv4): ConvTranspose2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (d_output): ConvTranspose2d(96, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (batchnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model=RedCNN()\n",
    "print(model)\n",
    "criterion=nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a993fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss:849.6525268554688 Batch:0\n",
      "Epoch: 0 Loss:445.1080322265625 Batch:10\n",
      "Epoch: 0 Loss:329.1041564941406 Batch:20\n",
      "Epoch: 0 Loss:282.9747009277344 Batch:30\n",
      "Epoch: 0 Loss:278.25848388671875 Batch:40\n",
      "Epoch: 0 Loss:268.8425598144531 Batch:50\n",
      "Epoch: 0 Loss:254.30479431152344 Batch:60\n",
      "Epoch: 0 Loss:261.08843994140625 Batch:70\n",
      "Epoch: 0 Loss:264.8851623535156 Batch:80\n",
      "Epoch: 0 Loss:259.65899658203125 Batch:90\n",
      "Epoch: 0 Loss:261.24163818359375 Batch:100\n",
      "Epoch: 0 Loss:250.15689086914062 Batch:110\n",
      "Epoch: 0 Loss:246.88502502441406 Batch:120\n",
      "Epoch: 0 Loss:257.6952209472656 Batch:130\n",
      "Epoch: 0 Loss:244.6479034423828 Batch:140\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m losses_batch\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 24\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (i\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m10\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ##Training\n",
    "optimizer.zero_grad()\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(testset, batch_size=32, shuffle=True)\n",
    "\n",
    "for epoch in range(1):\n",
    "    losses_batch=[]\n",
    "    trained_psnr=[]\n",
    "    for i, data in enumerate(train_loader):\n",
    "        \n",
    "        inputt, target=data\n",
    "        \n",
    "        target_pred=model(inputt)\n",
    "        \n",
    "        img=inputt.detach().numpy()\n",
    "        recon_image=target_pred.detach().numpy()\n",
    "        for j in range(len(target)):\n",
    "            trained_psnr.append(cv2.PSNR(img[j],recon_image[j]))\n",
    "        \n",
    "        loss=criterion(target_pred,target)\n",
    "        losses_batch.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i%10==0):\n",
    "            print(f\"Epoch: {epoch} Loss:{loss.item()} Batch:{i}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7105e740",
   "metadata": {},
   "outputs": [],
   "source": [
    "fisher_dict={}\n",
    "param_dict={}\n",
    "            \n",
    "for name, param in model.named_parameters():\n",
    "    param_dict[name] = param.data.clone()\n",
    "    fisher_dict[name] = param.grad.data.clone().pow(2)\n",
    "\n",
    "modelfile=\"trained_on_cat_130batch.pth.tar\"\n",
    "\n",
    "torch.save(model.state_dict(),modelfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0166b894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth PSNR: 18.774365291733467\n",
      "PSNR after training: 21.489992950461797\n"
     ]
    }
   ],
   "source": [
    "gt_psnr=[]\n",
    "\n",
    "for i in range(len(trainset)):\n",
    "    noise,gt=trainset[i]\n",
    "    gt_psnr.append(cv2.PSNR(noise.numpy(),gt.numpy()))\n",
    "    \n",
    "    \n",
    "print(f\"Ground Truth PSNR: {sum(gt_psnr)/len(gt_psnr)}\")\n",
    "print(f\"PSNR after training: {sum(trained_psnr)/len(trained_psnr)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd65b55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
